{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "name": "assignment_07.ipynb.txt",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sowmith8899/data690_skola2/blob/main/assignment_06/assignment_06.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "02rFSC_-6zKz"
      },
      "source": [
        "## Assignment 06\n",
        "### Note:\n",
        "- For visualization, you should use Plotly Express \n",
        "- Use this notebook as your template and follow the instructions\n",
        "\n",
        "The first half of this assignment is similar to assignment 04.\n",
        "\n",
        "This gives you a chance to refresh.\n",
        "\n",
        "The second half is new and gives you a chance to perform additional practices.\n",
        "\n",
        "You also get a chance to use some of the Python libraries and techniques.\n",
        "\n",
        "The links to the zip file is:\n",
        "\n",
        "- https://collegescorecard.ed.gov/data (This web page contains the link to the zip file)\n",
        "\n",
        "- https://ed-public-download.app.cloud.gov/downloads/CollegeScorecard_Raw_Data_09012022.zip (The link to the zip file)\n",
        "\n",
        "You can run `!wget` command in Colab notebook to retrieve it directly, then run `!unzip` command to extract files (I have provided the cells to do so next for your convenience)\n",
        "\n",
        "Your folder structure should look like this in your Colab enviroment:\n",
        "\n",
        "- ...\n",
        "- 'MERGED1996_97_PP.csv',\n",
        "- 'MERGED2015_16_PP.csv',\n",
        "- ...\n",
        "- 'MERGED2017_18_PP.csv'\n",
        "- ...\n",
        "\n",
        "**Note: you should refresh the folder to see all files.**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 1 - Retrieve the zip file"
      ],
      "metadata": {
        "id": "RemUiHBXf5EK"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IlnBrYreEoY2",
        "outputId": "ab72e375-7995-468c-e1ae-948346fa9b4e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!wget https://ed-public-download.app.cloud.gov/downloads/CollegeScorecard_Raw_Data_09012022.zip"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-10-09 20:49:55--  https://ed-public-download.app.cloud.gov/downloads/CollegeScorecard_Raw_Data_09012022.zip\n",
            "Resolving ed-public-download.app.cloud.gov (ed-public-download.app.cloud.gov)... 3.30.49.38, 3.30.138.208, 2600:1f12:18a:7d01:ad67:f64c:95d6:78ed, ...\n",
            "Connecting to ed-public-download.app.cloud.gov (ed-public-download.app.cloud.gov)|3.30.49.38|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 410294884 (391M) [application/zip]\n",
            "Saving to: ‘CollegeScorecard_Raw_Data_09012022.zip’\n",
            "\n",
            "CollegeScorecard_Ra 100%[===================>] 391.29M  44.4MB/s    in 9.4s    \n",
            "\n",
            "2022-10-09 20:50:05 (41.7 MB/s) - ‘CollegeScorecard_Raw_Data_09012022.zip’ saved [410294884/410294884]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2 - Unzip the zip file"
      ],
      "metadata": {
        "id": "mY5iKlaef_E3"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WXcix8Q4EWzN",
        "outputId": "13f6163e-a1b9-4e1b-d0e9-b7fa00a37372",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!unzip CollegeScorecard_Raw_Data_09012022.zip"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  CollegeScorecard_Raw_Data_09012022.zip\n",
            " extracting: Crosswalks.zip          \n",
            "  inflating: data.yaml               \n",
            "  inflating: FieldOfStudyData1415_1516_PP.csv  \n",
            "  inflating: FieldOfStudyData1516_1617_PP.csv  \n",
            "  inflating: FieldOfStudyData1617_1718_PP.csv  \n",
            "  inflating: FieldOfStudyData1718_1819_PP.csv  \n",
            "  inflating: MERGED1996_97_PP.csv    \n",
            "  inflating: MERGED1997_98_PP.csv    \n",
            "  inflating: MERGED1998_99_PP.csv    \n",
            "  inflating: MERGED1999_00_PP.csv    \n",
            "  inflating: MERGED2000_01_PP.csv    \n",
            "  inflating: MERGED2001_02_PP.csv    \n",
            "  inflating: MERGED2002_03_PP.csv    \n",
            "  inflating: MERGED2003_04_PP.csv    \n",
            "  inflating: MERGED2004_05_PP.csv    \n",
            "  inflating: MERGED2005_06_PP.csv    \n",
            "  inflating: MERGED2006_07_PP.csv    \n",
            "  inflating: MERGED2007_08_PP.csv    \n",
            "  inflating: MERGED2008_09_PP.csv    \n",
            "  inflating: MERGED2009_10_PP.csv    \n",
            "  inflating: MERGED2010_11_PP.csv    \n",
            "  inflating: MERGED2011_12_PP.csv    \n",
            "  inflating: MERGED2012_13_PP.csv    \n",
            "  inflating: MERGED2013_14_PP.csv    \n",
            "  inflating: MERGED2014_15_PP.csv    \n",
            "  inflating: MERGED2015_16_PP.csv    \n",
            "  inflating: MERGED2016_17_PP.csv    \n",
            "  inflating: MERGED2017_18_PP.csv    \n",
            "  inflating: MERGED2018_19_PP.csv    \n",
            "  inflating: MERGED2019_20_PP.csv    \n",
            "  inflating: MERGED2020_21_PP.csv    \n",
            "  inflating: Most-Recent-Cohorts-Field-of-Study.csv  \n",
            "  inflating: Most-Recent-Cohorts-Institution.csv  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 3 - Import Libraries"
      ],
      "metadata": {
        "id": "3gWAI-4_gCs2"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CfSasSG36zK1"
      },
      "source": [
        "#(Write code below)\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.graph_objects as go\n",
        "import os"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 4 - Display the current working directory using os.getcwd()\n",
        "\n",
        "You would need to import a standard Python library called os which stands for operating system. so place that import statement in the previous cell. Since your notebook and your data files may or may not in the same folder, you want to make sure what the current working folder is and how to access a data file in a different folder."
      ],
      "metadata": {
        "id": "zNVWs_R9gKrr"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "duwKxi1L6zK5",
        "outputId": "a907f03a-beed-495b-c1d2-5bec240fcd46",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#(Write code below)\n",
        "dir = os.getcwd()\n",
        "dir"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 5 - Get the list of file names\n",
        "\n",
        "os library has a method call listdir which generates a list of files in a directory/folder. Use this method to assign the contents (list of file names) of the data folder to a variable and display it. If necessary, you can use ../ construct to traverse to the parent folder and then to another foloder parallel to the current folder\n"
      ],
      "metadata": {
        "id": "SxFHpsKSgxzv"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LMBN0HsY6zLA",
        "outputId": "1270b186-0a35-44e4-eac6-83caf14d951e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#(Write code below)\n",
        "files =os.listdir(dir)\n",
        "files"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['.config',\n",
              " 'MERGED2006_07_PP.csv',\n",
              " 'MERGED2009_10_PP.csv',\n",
              " 'MERGED2003_04_PP.csv',\n",
              " 'MERGED1998_99_PP.csv',\n",
              " 'Crosswalks.zip',\n",
              " 'MERGED2012_13_PP.csv',\n",
              " 'MERGED2019_20_PP.csv',\n",
              " 'MERGED2011_12_PP.csv',\n",
              " 'MERGED2014_15_PP.csv',\n",
              " 'Most-Recent-Cohorts-Field-of-Study.csv',\n",
              " 'MERGED2000_01_PP.csv',\n",
              " 'MERGED2007_08_PP.csv',\n",
              " 'MERGED2016_17_PP.csv',\n",
              " 'FieldOfStudyData1718_1819_PP.csv',\n",
              " 'MERGED2018_19_PP.csv',\n",
              " 'MERGED2008_09_PP.csv',\n",
              " 'MERGED2002_03_PP.csv',\n",
              " 'MERGED2004_05_PP.csv',\n",
              " 'MERGED2010_11_PP.csv',\n",
              " 'MERGED2013_14_PP.csv',\n",
              " 'MERGED2005_06_PP.csv',\n",
              " 'FieldOfStudyData1516_1617_PP.csv',\n",
              " 'MERGED1999_00_PP.csv',\n",
              " 'MERGED2015_16_PP.csv',\n",
              " 'MERGED1996_97_PP.csv',\n",
              " 'FieldOfStudyData1415_1516_PP.csv',\n",
              " 'FieldOfStudyData1617_1718_PP.csv',\n",
              " 'MERGED2017_18_PP.csv',\n",
              " 'data.yaml',\n",
              " 'Most-Recent-Cohorts-Institution.csv',\n",
              " 'MERGED1997_98_PP.csv',\n",
              " 'MERGED2020_21_PP.csv',\n",
              " 'CollegeScorecard_Raw_Data_09012022.zip',\n",
              " 'MERGED2001_02_PP.csv',\n",
              " 'sample_data']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 6 - Process only the yearly data files\n",
        "\n",
        "The folder contains files that are not the yearly data files. Write code to remove the unwanted files from the list variable.\n",
        "\n",
        "Note: don't remove/delete these files from the folder in the folder.\n",
        "For example, use the file extension to only use the csv files or use the name patter - data file name begins with \"MERGED\". You can use the concept of list comprehension to write just *one* line of code as well as using a for loop, your choice."
      ],
      "metadata": {
        "id": "XtKgf-SMhL0z"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UCDRqtrf6zLL",
        "outputId": "347f22d0-7ca4-4b37-f1b5-f6bf01d68d71",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#(Write code below)\n",
        "yearly = [x for x in files if \"MERGED\" in x]\n",
        "yearly"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['MERGED2006_07_PP.csv',\n",
              " 'MERGED2009_10_PP.csv',\n",
              " 'MERGED2003_04_PP.csv',\n",
              " 'MERGED1998_99_PP.csv',\n",
              " 'MERGED2012_13_PP.csv',\n",
              " 'MERGED2019_20_PP.csv',\n",
              " 'MERGED2011_12_PP.csv',\n",
              " 'MERGED2014_15_PP.csv',\n",
              " 'MERGED2000_01_PP.csv',\n",
              " 'MERGED2007_08_PP.csv',\n",
              " 'MERGED2016_17_PP.csv',\n",
              " 'MERGED2018_19_PP.csv',\n",
              " 'MERGED2008_09_PP.csv',\n",
              " 'MERGED2002_03_PP.csv',\n",
              " 'MERGED2004_05_PP.csv',\n",
              " 'MERGED2010_11_PP.csv',\n",
              " 'MERGED2013_14_PP.csv',\n",
              " 'MERGED2005_06_PP.csv',\n",
              " 'MERGED1999_00_PP.csv',\n",
              " 'MERGED2015_16_PP.csv',\n",
              " 'MERGED1996_97_PP.csv',\n",
              " 'MERGED2017_18_PP.csv',\n",
              " 'MERGED1997_98_PP.csv',\n",
              " 'MERGED2020_21_PP.csv',\n",
              " 'MERGED2001_02_PP.csv']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 7 - Load data files\n",
        " \n",
        "Now that you have a clean list of the yearly files, you want to loop through them and read them into a dataframe one at a time. You only load six columns: [\"UNITID\", \"INSTNM\", \"STABBR\", \"REGION\", \"ADM_RATE\", \"TUITIONFEE_IN\"].\n",
        "\n",
        "You should use \"usecols\" option of Pandas to avoid reading unwanted columns. You also want to add a new column call \"YEAR\" to differentiate the data frames from each other. The YEAR variable should be yyyy format so tht you can convert them into integer. If you use the format yyyy-yy (such as 1997-98 school year), you will not be able to convert them directly to integer. If you use scatter plot, the YEAR needs to be converted to integer or float. \n",
        "\n",
        "You would use an empty list and append the yearly dataframes to the list. After all data files are loaded and appended to the list, you would use Pandas to concatenate them into a new single data frame.\n",
        "\n",
        "Note: this exercise incorporates many techques we learned before:\n",
        "\n",
        "- list (creating an empty, append an item to the list)\n",
        "- for loop \n",
        "- read only the needed columns from a file (using usecols option)\n",
        "- add a new column to a data frame\n",
        "- concatenate multiple dataframes into a single one\n",
        "\n",
        "This exercise may appear challenging but it worths the effort. You will learn a lot and love it. I promise."
      ],
      "metadata": {
        "id": "UbrfZBRThtG8"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rtrB8C_R6zLS",
        "outputId": "06d928ab-82b5-4b84-a557-f0dbd4a2b8c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 371
        }
      },
      "source": [
        "#(Write code here)\n",
        "li = []\n",
        "\n",
        "def yearly_files(fname):\n",
        "    df = pd.read_csv(fname,usecols=['UNITID', 'INSTNM', 'STABBR' , 'REGION' , 'ADM_RATE' , 'TUITIONFEE_IN'])\n",
        "    df['year'] = fname.split('/')[1].split(\"_\")[0].replace('MERGED','')\n",
        "    li.append(df)  \n",
        "    return df  \n",
        "\n",
        "for fname in files :\n",
        "  yearly_files(fname)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IsADirectoryError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIsADirectoryError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-448041565cbd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfiles\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m   \u001b[0myearly_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-12-448041565cbd>\u001b[0m in \u001b[0;36myearly_files\u001b[0;34m(fname)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0myearly_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'UNITID'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'INSTNM'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'STABBR'\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;34m'REGION'\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;34m'ADM_RATE'\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;34m'TUITIONFEE_IN'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'year'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"_\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'MERGED'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mli\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    227\u001b[0m             \u001b[0mmemory_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m             \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"encoding_errors\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"strict\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m         )\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    705\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 707\u001b[0;31m                 \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    708\u001b[0m             )\n\u001b[1;32m    709\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIsADirectoryError\u001b[0m: [Errno 21] Is a directory: '.config'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 8 - Explore the new dataframe \n",
        "\n",
        "For example, # of observations, varibles, head, tail, sample, missing values, statistics, etc."
      ],
      "metadata": {
        "id": "M-OsDFXFiZd-"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "riJxj3vU6zLY"
      },
      "source": [
        "#(Write code here)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 9 - UMBC \n",
        "\n",
        "The dataframe contains many years of data of all U.S. colleges. let's just look at UMBC. Filter/query the dataframe to retrieve only rows that belong to UMBC (one row represent one year). Save the UMNC data to a new data frame. using a new variable for the UMBC data frame, so that the old big data frame is still available for later use."
      ],
      "metadata": {
        "id": "odf117B-ip7D"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQjKoDmU6zLd"
      },
      "source": [
        "#(Write code here)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 10 - Explore the new dataframe\n",
        "\n",
        "For example, # of observations, varibles, head, tail, sample, missing values, statistics, etc"
      ],
      "metadata": {
        "id": "JEwabb0PjCmT"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5X87ugp6zLt"
      },
      "source": [
        "#(Write code here)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 11 - Plot UMBC's in-state tution overtime Bar Chart"
      ],
      "metadata": {
        "id": "yhkk1v-KjNu-"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Poy4ciz6zLy"
      },
      "source": [
        "#(Write code here)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 12 - Plot UMBC's in-state tution overtime using line Chart"
      ],
      "metadata": {
        "id": "85qFArw4jXnP"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "afOQjc1w6zL4"
      },
      "source": [
        "#(Write code here)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 13 - Tuition Growth Rate\n",
        "\n",
        "Now let's look at the tuition growth rate year over year. We need to calculate UMBC tuition change percentage each year. First convert the TUITIONFEE_IN column to a Python List"
      ],
      "metadata": {
        "id": "5FH2h2_ajlKE"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQLB2f7J6zL-"
      },
      "source": [
        "#(Write code here)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 14 - Loop through the list and calculate the % change each year over the prior year\n",
        "\n",
        "This takes some effort. Not hard, just some abstract/logical thinking and some experiments. Have fun on this one."
      ],
      "metadata": {
        "id": "e4OhAzjlj3tw"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LRUyQCtJ6zMB"
      },
      "source": [
        " #(Write code here)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 15 - Round up the percentage to two decimal points\n",
        "\n",
        "The resulting number has many decimal points which are unnecessary and not visually appealing. You can use for loop. Or better, use list comprehension for simplicity/brevity."
      ],
      "metadata": {
        "id": "vLogjxM1kSDH"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9sxMk1hc6zML"
      },
      "source": [
        "#(Write code here)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 16 - Add the list of the percentages to the dataframe as a new column (\"PCT_CHANGE\")\n",
        "\n",
        "Not as hard as you may think. If you get stuck, you think too hard. Google it and you will find the answer."
      ],
      "metadata": {
        "id": "cWK8vDitkLpx"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_04rVaZ16zMR"
      },
      "source": [
        "#(Write code here)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 17 - Finaly, we can make the plot tuition growth rate year over year - bar first, then line chart"
      ],
      "metadata": {
        "id": "aVcm3NltknpE"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Evbjx-g6zMX"
      },
      "source": [
        "# (write code here)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 18 - Define Growth Rate Function\n",
        "\n",
        "Since we want to do the same calculation for JHU. Instead of doing it piecemeal as we did for UMBC. Let's create a function which can be reused for any college. This function takes a list of tuitions and return a list of percentage changes year over year. This function can be used later."
      ],
      "metadata": {
        "id": "V1TiCardmjU2"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eCqEe_646zMc"
      },
      "source": [
        "#(Write code here)\n",
        "\n",
        " "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 19 - Get JHU Data\n",
        "\n",
        "The dataframe contains many years of data of all U.S. colleges. Let's just look at JHU. Filter/query the dataframe to retrieve only rows that belong to JHU. Save the JHU data to a new data frame using a new variable so that the old big data frame is still available for later use."
      ],
      "metadata": {
        "id": "U2jqd5GYmy3Z"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f2mhYOjV6zMj"
      },
      "source": [
        "#(Write code here)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 20 - Plot JHU's in-state tuition overtime\n",
        "\n",
        "Let's plot bar and then line chart."
      ],
      "metadata": {
        "id": "VkyEUa6mnKgD"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wGXcNTJ46zMo"
      },
      "source": [
        "# <14> \n",
        "# Plot JHU's in-state tuition overtime from 1996 to 2019. \n",
        "# Let's plot bar and line chart together\n",
        "\n",
        "#(Write code here)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 21 - Calculate Tuition Growth Rate using the Function defined earlier\n"
      ],
      "metadata": {
        "id": "wNn0AXexnsxq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write code here"
      ],
      "metadata": {
        "id": "q5xcRlLMn4Ap"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 22 - Add the list of percentage changes to the dataframe as a new column (\"PCT_CHANGE\")"
      ],
      "metadata": {
        "id": "HSPcfvsGn8MG"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7KM74FQH6zM4"
      },
      "source": [
        "#(Write code here)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 23 - Plot the JHU percentage changes tuitions over time\n",
        "\n",
        "Bar plot first, then line plot."
      ],
      "metadata": {
        "id": "LPei7NtpoFFb"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vGi8YI_A6zM7"
      },
      "source": [
        "#(Write code here)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 24 - Compare UMBC and JHU \n",
        "\n",
        "In order to plot both UMBC and JHU tuition change over time in the same plot, we need to combine the two datasets using the common key of YEAR. \n",
        "\n",
        "First make a umbc2 dataframe with only two columns needed. We don't need other columns. Also change the column name from \"PCT_CHANGE\" to \"UMBC_PCT\" in preparation for the merge. This is because both umbc and jhu dataframe have the same column name \"PCT_CHANGE\", we rename them to there is no collision during the merge. BTW, Pandas handles collision gracefully, Feel free to try it without changing the column names."
      ],
      "metadata": {
        "id": "CBHqIJBcoXv-"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bGYYULq16zNA"
      },
      "source": [
        "#(Write code here)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 25 \n",
        "\n",
        "Then make a jhu2 dataframe with only two columns needed. WE don't need other columns. Also change the column name from \"PCT_CHANGE\" to \"JHU_PCT\"  in preparation for the merge"
      ],
      "metadata": {
        "id": "W23PSBYmozzi"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DX95nFyG6zNF"
      },
      "source": [
        "#(Write code here)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 26 - Merger the two data frames and display the new dataframe"
      ],
      "metadata": {
        "id": "Q19tgEntpBsD"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJ_6wKKU6zNL"
      },
      "source": [
        "#(Write code here)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 27 - Plot UMBC and JHU separately on the same line plot "
      ],
      "metadata": {
        "id": "dWdOJl19pXud"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "hyClyzNepVrH"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ng3bbP076zNW"
      },
      "source": [
        "#(Write code here)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6YNmMkgW6zNv"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 28 - Document your observation of the comparison plots using the following Markdown cell"
      ],
      "metadata": {
        "id": "Pw6GMGUwpjz6"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tzeP_v8E6zNz"
      },
      "source": [
        "#### Based on my observation of the plots\n",
        "#### blah, blah \n",
        "#### blah, blah\n",
        "#### ...\n",
        "#### blah, blah"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "njPmmLLA6zN0"
      },
      "source": [
        "# The end."
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}